{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "NOTE: Assuming no repeats, as informed\n",
    "For timeseries, we want aggregated by date the frequency of each crime type. For example:\n",
    "row 1: 1/1/2018 Theft: 12, Destruction/...: 22, etc. \n",
    "As many features as the 24 offense types (codes 13A, 13B, 13C, 13D are recoded as 13, etc.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Creating Bi-Monthly DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding offense codes into the 24 options\n",
    "def new_offense_code(prior):\n",
    "    if prior.isnumeric():\n",
    "        return prior\n",
    "    return prior[:2]\n",
    "\n",
    "# gets 'Incident Date' feature in correct order\n",
    "def reorder_dates(bimonthly_df):\n",
    "    # puts incident dates in order\n",
    "    days = list(set(bimonthly_df['Incident Date']))\n",
    "    try:\n",
    "        days.sort(key=lambda date: datetime.strptime(date, \"%m/%d/%Y\"))\n",
    "    except ValueError:\n",
    "        days.sort(key=lambda date: datetime.strptime(date, \"%m/%d/%y\"))\n",
    "\n",
    "    # gets index values in the order by date\n",
    "    order = []\n",
    "    for day in days:\n",
    "        i = bimonthly_df.loc[bimonthly_df['Incident Date'] == day].index[0]\n",
    "        order.append(i)\n",
    "    # reindex to order dates in ascending order\n",
    "    bimonthly_cleaned_df = bimonthly_df.reindex(order)\n",
    "    # reset index to start with 0\n",
    "    bimonthly_cleaned_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return bimonthly_cleaned_df\n",
    "\n",
    "# create the aggregated by code count df\n",
    "def create_bimonthyl_code_df(df):\n",
    "    df['Code'] = df['Offense Code'].apply(new_offense_code)\n",
    "\n",
    "    # extract monthly period\n",
    "    months = '_'.join(df['Incident Month'].unique().tolist())\n",
    "\n",
    "    # trim features\n",
    "    dfx = df[['ORI','Incident Number','Incident Date','Code']]\n",
    "\n",
    "    # expand Code as features (this doesn't guaruntee that 24 codes will come up, technically a month could not have a certain crime)\n",
    "    X = pd.get_dummies(dfx.Code, prefix='Code')\n",
    "    dfy = pd.concat([dfx,X], axis=1).drop('Code', axis=1)\n",
    "\n",
    "    # aggregate by count of code by date\n",
    "    bimonthly_df = dfy.groupby(['Incident Date']).sum()\n",
    "\n",
    "    # make 'Incident Date' a feature again instead of index\n",
    "    bimonthly_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    return months, reorder_dates(bimonthly_df=bimonthly_df)\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working over files in Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directory\n",
    "d = '../Data/TBI2018-20/'\n",
    "# prepping dictionary for file names\n",
    "yl = {\n",
    "    '2018':[],\n",
    "    '2019':[],\n",
    "    '2020':[],\n",
    "}\n",
    "# getting files to run by year\n",
    "for year in ['2018', '2019', '2020']:\n",
    "    for file in os.listdir(d):\n",
    "        if year in file:\n",
    "            yl[year].append(d + file)\n",
    "\n",
    "# ordering files chronologically \n",
    "yl['2018'] = [yl['2018'][i] for i in [1,4,5,2,3,0]]\n",
    "yl['2019'] = [yl['2019'][i] for i in [0,2,3,4,5,1]]\n",
    "yl['2020'] = [yl['2020'][i] for i in [5,2,3,0,1,4]]\n",
    "\n",
    "# ordering features for concatonation consistency\n",
    "ordered_cols = [\n",
    "    'Incident Date',\n",
    "    'Code_09',\n",
    "    'Code_11',\n",
    "    'Code_13',\n",
    "    'Code_23',\n",
    "    'Code_26',\n",
    "    'Code_35',\n",
    "    'Code_36',\n",
    "    'Code_39',\n",
    "    'Code_40',\n",
    "    'Code_64',\n",
    "    'Code_100',\n",
    "    'Code_120',\n",
    "    'Code_200',\n",
    "    'Code_210',\n",
    "    'Code_220',\n",
    "    'Code_240',\n",
    "    'Code_250',\n",
    "    'Code_270',\n",
    "    'Code_280',\n",
    "    'Code_290',\n",
    "    'Code_370',\n",
    "    'Code_510',\n",
    "    'Code_520',\n",
    "    'Code_720'\n",
    "]\n",
    "\n",
    "# will have master file\n",
    "# all_df = pd.DataFrame()\n",
    "\n",
    "for year in list(yl.keys()):\n",
    "    # reset yearly df\n",
    "    yearly_df = pd.DataFrame()\n",
    "\n",
    "    for file in yl[year]:\n",
    "        # read in bimonthly csv\n",
    "        bimonthly_df = pd.DataFrame()\n",
    "        bimonthly_df = pd.read_csv(file, encoding='ISO-8859-1',skiprows=5)\n",
    "        # get the months for the new file, prepped bimonthly df\n",
    "        \n",
    "        months, cleaned_monthly_df = create_bimonthyl_code_df(bimonthly_df)\n",
    "    \n",
    "        # need to order columns to match\n",
    "        cleaned_monthly_df = cleaned_monthly_df[ordered_cols]\n",
    "        # export bimonthly to csv\n",
    "        cleaned_monthly_df.to_csv(f'../Data/TBI2018-20_cleaned/Bi-monthly/{months}_{year}_cleaned.csv')\n",
    "        # concat the yearly csv\n",
    "        if yearly_df.empty:\n",
    "            yearly_df = cleaned_monthly_df\n",
    "        else:\n",
    "            yearly_df = pd.concat([yearly_df,cleaned_monthly_df],axis=0)\n",
    "    \n",
    "    # fix index\n",
    "    yearly_df.reset_index(drop=True, inplace=True)\n",
    "    # export yearly file\n",
    "    yearly_df.to_csv(f'../Data/TBI2018-20_cleaned/Yearly/year_{year}_compiled.csv')\n",
    "    # # concat the master csv\n",
    "    # if all_df.empty:\n",
    "    #     all_df = yearly_df\n",
    "    # else:\n",
    "    #     all_df = pd.concat([all_df, yearly_df], axis=0)\n",
    "\n",
    "# export master file\n",
    "# all_df.to_csv(f'../Data/TBI2018-20_cleaned/master_2018-2020.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating master file\n",
    "X = pd.read_csv('../Data/TBI2018-20_cleaned/Yearly/year_2018_compiled.csv')\n",
    "Y = pd.read_csv('../Data/TBI2018-20_cleaned/Yearly/year_2019_compiled.csv')\n",
    "Z = pd.read_csv('../Data/TBI2018-20_cleaned/Yearly/year_2020_compiled.csv')\n",
    "\n",
    "all_df = pd.concat([X,Y,Z], axis=0)\n",
    "all_df.reset_index(drop=True, inplace=True)\n",
    "all_df.to_csv('../Data/TBI2018-20_cleaned/master_2018-2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Issue with delinquent files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading in jan-feb 2018 for a look see what prep is needed\n",
    "df = pd.read_csv('../Data/TBI2018-20/May-Jun 2019 Offense Data.csv', encoding='ISO-8859-1',skiprows=5)\n",
    "# df2 = pd.read_csv('../Data/TBI2018-20/Nov-Dec 2019 Offense Data.csv', encoding='ISO-8859-1',skiprows=5)\n",
    "\n",
    "# # fixed this for the delinquent files. In each of them someone misentered address info that caused the address \n",
    "# # to spill into multiple cell entries, so these rows had entries on up to 4 extra columns\n",
    "# df['Incident Month'].unique().tolist() # ['December', 'November', '37055\"', '37036\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df['Incident Date'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m, ndf = create_bimonthyl_code_df(df)\n",
    "# # m2,ndf2 = create_bimonthyl_code_df(df2)\n",
    "# print(m)\n",
    "# ndf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
